---
layout: article
title: 04. CS231N ìš”ì•½ (RNN and Other models)
author: J_å®‹
tags: ComputerVision CS231n í•œê¸€
mathjax: true
key: ComputerVision04
---



#### Recurrent Neural Network

##### Recurent Networkì˜ ì¢…ë¥˜ë“¤ :

 <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-02 at 5.48.33 PM.png" alt="Screen Shot 2021-08-02 at 5.48.33 PM" style="zoom:30%;" />

- One to many : 

  Ex. Image Captioning : ì´ë¯¸ì§€ë¥¼ ë¬˜ì‚¬í•˜ëŠ” ë‹¨ì–´ë“¤ì˜ sequenceë¥¼ ì¶œë ¥

- Many to one :

  Ex. Sentiment Classification : ë‹¨ì–´ë“¤ë¡œ êµ¬ì„±ëœ sequence(íŠ¸ìœ„í„° ë©”ì„¸ì§€ ê°™ì€ ê²ƒ)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ê°ì •ì„ ë¶„ë¥˜í•¨

- Many to many :

  Ex. Machine Translation : ì˜ì–´ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ë¬¸ì¥ì´ ë“¤ì–´ì™”ì„ ë•Œ, í•œêµ­ì–´ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­

- Many to many :

  Ex. Video Classification on frame level : ë¹„ë””ì˜¤ì—ì„œ frameí•˜ë‚˜í•˜ë‚˜ë¥¼ classificationì„ í•¨

  - ì˜ˆì¸¡ì´ í˜„ì¬ ì‹œì ì˜ frameì— êµ­í•œë˜ë©´ ì•ˆë¨
  - ë¹„ë””ì˜¤ ì˜ˆì¸¡ì€ í˜„ì¬ ì‹œì ì˜ frameê³¼ í˜„ì¬ ì‹œì  ì „ì— ì§€ë‚˜ê°„ ëª¨ë“  frameë“¤ì— ëŒ€í•œ í•¨ìˆ˜ê°€ ë˜ì–´ì•¼ë¨   



##### RNNì˜ ê³¼ì •

<img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 3.30.23 PM.png" alt="Screen Shot 2021-08-03 at 3.30.23 PM" style="zoom:25%;" />

- ***x*** : input vector

- ***RNN*** :  

  - ë‚´ë¶€ì ìœ¼ë¡œ stateë¥¼ ê°€ì§

  - stateë¥¼ functionìœ¼ë¡œ ë³€í˜• ì‹œí‚¬ ìˆ˜ ìˆìŒ

  - Weightë¡œ êµ¬ì„±ë˜ë©° Weightë“¤ì´ íŠœë‹ë˜ì–´ê°ì— ë”°ë¼ì„œ RNNì´ ì§„í™”ë˜ì–´ë‚˜ê°€ê¸° ë•Œë¬¸ì—, ìƒˆë¡œìš´ inputì´ ë“¤ì–´ì˜¬ë•Œ ë§ˆë‹¤ ë‹¤ë¥¸ ë°˜ì‘ì„ ë³´ì„

  - ë§¤ time step ë§ˆë‹¤ ì…ë ¥ë˜ëŠ” vectorì— ëŒ€í•´ì„œ *recurrence function*ì„ ì ìš©í•  ìˆ˜ ìˆìŒ.  *recurrence function*ì„ ì ìš©í•¨ìœ¼ë¡œì¨ sequenceë¥¼ ì²˜ë¦¬í•´ ì¤„ ìˆ˜ ìˆê²Œë¨ :

     <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 3.29.53 PM.png" alt="Screen Shot 2021-08-03 at 3.29.53 PM" style="zoom:30%;" />

    - State : Vectorì˜ collection

      *:warning: ëª¨ë“  time stepì—ì„œ ë™ì¼í•œ recurrence function ê³¼ ë™ì¼í•œ parameterê°€ ì‚¬ìš©ë¨*

- ***y*** : ìš°ë¦¬ëŠ” íŠ¹ì • time stepì—ì„œì˜ vectorì˜ ì˜ˆì¸¡ì„ ì›í•¨ 



***Example.***  RNNì—ê²Œ Character sequence ("hello") ë¥¼ feedingì„ ì‹œí‚¤ê³  ë§¤ ìˆœê°„ì˜ time stepì—ì„œ RNNì—ê²Œ ë‹¤ìŒ stepì— ì–´ë–¤ Characterê°€ ì™€ì•¼ë˜ëŠ”ì§€ ë¬»ëŠ” ê²ƒ 

 <img src="/assets/images/è®¡è§†/myNote/pic04/3-49 screenshot.png" alt="3-49 screenshot" style="zoom:65%;" />

- W_hh : hidden ì—ì„œ hiddenìœ¼ë¡œ ì´ë™í•˜ëŠ” weight
- W_xh : xì—ì„œ hiddenìœ¼ë¡œ ì´ë™í•˜ëŠ” weight
- W_hy : hidden ì—ì„œ yìœ¼ë¡œ ì´ë™í•˜ëŠ” weight



##### Implementation using NumPy

###### Data Input/Output

```python
import numpy as np

data = open('input.txt', 'r').read() # should be simple plain text file
chars = list(set(data))
data_size, vocab_size = len(data), len(chars)
print 'data has %d characters, %d unique.' % (data_size, vocab_size)
char_to_ix = { ch:i for i,ch in enumerate(chars) }
ix_to_char = { i:ch for i,ch in enumerate(chars) }
```

- `enumerate()` : index ë²ˆí˜¸ì™€ listì˜ ì›ì†Œë¥¼ tupleí˜•íƒœë¡œ returní•¨

  ```python
  >>> t = [1, 5, 7, 33, 39, 52]
  >>> for p in enumerate(t):
  ...     print(p)
  ... 
  (0, 1)
  (1, 5)
  (2, 7)
  (3, 33)
  (4, 39)
  (5, 52)
  ```



###### Initialization

```python
# hyperparameters
hidden_size = 100 # size of hidden layer of neurons
seq_length = 25 # number of steps to unroll the RNN for
learning_rate = 1e-1 #10^(-1)

# model parameters
Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden
Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden
Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output
bh = np.zeros((hidden_size, 1)) # hidden bias
by = np.zeros((vocab_size, 1)) # output bias
```

- `seq_length` : ì…ë ¥ëœ sequenceì˜ ê¸¸ì´ ì œì•½ì„ ë‘¬ì„œ ì¼ê´„ ì²˜ë¦¬ í•  ìˆ˜ ìˆëŠ” ìˆ«ìë¥¼ ë‚˜íƒ€ëƒ„ 



###### Main loop

```python
n, p = 0, 0
mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)
mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad
smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0
while True:
  # input ì¤€ë¹„ ê³¼ì • 
  if p+seq_length+1 >= len(data) or n == 0: 
    hprev = np.zeros((hidden_size,1)) # reset RNN memory
    p = 0 # go from start of data
  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]
  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]

  # sample() í˜¸ì¶œ í•¨ìœ¼ë¡œ ì¨ í•™ìŠµì˜ ë§¤ time step ë§ˆë‹¤ ì˜ˆì¸¡í•˜ëŠ” characterë¥¼ outputìœ¼ë¡œ ì¶œë ¥ 
  if n % 100 == 0:
    sample_ix = sample(hprev, inputs[0], 200)
    txt = ''.join(ix_to_char[ix] for ix in sample_ix)
    print '----\n %s \n----' % (txt, )

  # Networkë¥¼ í†µí•´ 25ê°œ characterë¥¼ forward ì‹œí‚¨ ë‹¤ìŒ loss ê°’ êµ¬í•˜ê¸°
  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)
  smooth_loss = smooth_loss * 0.999 + loss * 0.001
  if n % 100 == 0: print 'iter %d, loss: %f' % (n, smooth_loss) # print progress
  
  # parameter ì—…ë°ì´íŠ¸
  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], 
                                [dWxh, dWhh, dWhy, dbh, dby], 
                                [mWxh, mWhh, mWhy, mbh, mby]):
    mem += dparam * dparam
    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update

  p += seq_length # move data pointer
  n += 1 # iteration counter 
```

- `hprev` : ì „ ë‹¨ê³„ì˜ hidden state vector 
  -  hidden state vectorê°€ batchì—ì„œ  batchë¡œ ì´ì–´ì§ˆ ë•Œ ì˜ porpagationì´ ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒ



###### Loss Function

```python
def lossFun(inputs, targets, hprev):
  """
  inputs : list of integers
  targets : list of integers
  hprev : Hx1 array of initial hidden state
  return : the loss, gradients on model parameters, and last hidden state
  """
  xs, hs, ys, ps = {}, {}, {}, {}
  hs[-1] = np.copy(hprev)
  loss = 0
  
  # forward pass
  for t in xrange(len(inputs)): # 25ë²ˆ ë°˜ë³µ
    xs[t] = np.zeros((vocab_size,1)) # input ë¶€ë¶„ one-hot encoding í•˜ê¸°
    xs[t][inputs[t]] = 1 						 # input ë¶€ë¶„ one-hot encoding í•˜ê¸°
    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) 
    ys[t] = np.dot(Why, hs[t]) + by 
    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))
    loss += -np.log(ps[t][targets[t],0])
    
  # backward pass: compute gradients going backwards
  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)
  dbh, dby = np.zeros_like(bh), np.zeros_like(by)
  dhnext = np.zeros_like(hs[0])
  for t in reversed(xrange(len(inputs))):  # 25ë¶€í„° 1ê¹Œì§€
    dy = np.copy(ps[t])
    dy[targets[t]] -= 1 # backprop into y.
    dWhy += np.dot(dy, hs[t].T)
    dby += dy
    dh = np.dot(Why.T, dy) + dhnext # backprop into h
    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity
    dbh += dhraw
    dWxh += np.dot(dhraw, xs[t].T)
    dWhh += np.dot(dhraw, hs[t-1].T)
    dhnext = np.dot(Whh.T, dhraw)
    
  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:
    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients
  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]
```

- forward pass 

  - `hs[t]` : <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 5.30.07 PM.png" alt="Screen Shot 2021-08-03 at 5.30.07 PM" style="zoom:30%;" />
  - `ys[t]` : <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 5.30.29 PM.png" alt="Screen Shot 2021-08-03 at 5.30.29 PM" style="zoom:30%;" />
  - `ps[t]` : Softmax function
  - `loss` : Cross entropy loss

- `np.clip()` : -5ì™€ 5ë¥¼ ë„˜ì–´ì„œë©´ ì´ ë²”ìœ„ ì•ˆì— ë“¤ì–´ì˜¤ë„ë¡ clipping í•´ì¤Œ

  ```python
  >>> a = np.arange(10)
  >>> a
  array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  >>> np.clip(a, 3, 6, out=a)
  array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
  >>> a
  array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
  ```

  - RNNì—ì„œëŠ” Gradientê°€ explodingë˜ëŠ” ë‹¨ì ì„ ì§€ë‹ˆê³  ìˆê¸° ë•Œë¬¸ì— ì‚¬ìš©ë¨



###### Sample

```python
def sample(h, seed_ix, n):
  """ 
  RNNì´ trainingì—ì„œ í•™ìŠµí•œ ê²ƒê³¼ characterë“¤ì´ í†µê³„ì— ê¸°ë°˜í•˜ì—¬ì„œ ìƒˆë¡œìš´ text ë°ì´í„°ë¥¼ ìƒì„±í•˜ë„ë¡ í•˜ëŠ” í•¨ìˆ˜  
  h : memory state
  seed_ix : seed letter for first time step
  """
  x = np.zeros((vocab_size, 1)) # ì…ë ¥ê°’ one-hot encoding
  x[seed_ix] = 1								# ì…ë ¥ê°’ one-hot encoding
  ixes = []
  for t in xrange(n):
    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)
    y = np.dot(Why, h) + by
    p = np.exp(y) / np.sum(np.exp(y))
    ix = np.random.choice(range(vocab_size), p=p.ravel())
    x = np.zeros((vocab_size, 1)) # ê²°ê³¼ê°’ one-hot encoding
    x[ix] = 1											# ê²°ê³¼ê°’ one-hot encoding
    ixes.append(ix)
  return ixes
```

- `h` : <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 5.30.07 PM.png" alt="Screen Shot 2021-08-03 at 5.30.07 PM" style="zoom:30%;" />
- `y` : <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 5.30.29 PM.png" alt="Screen Shot 2021-08-03 at 5.30.29 PM" style="zoom:30%;" />
- `p` : Softmax function



##### Experiment 

<img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 5.58.39 PM.png" alt="Screen Shot 2021-08-03 at 5.58.39 PM" style="zoom:40%;" />

- ìƒì„±ëœ C ì½”ë“œì—ì„œ Syntax errorë¬¸ì œë“¤( ë³€ìˆ˜ ì„ ì–¸í•˜ê³  ëê¹Œì§€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, ë³€ìˆ˜ ì„ ì–¸ ì•ˆí•˜ê³  ì‚¬ìš© ë“±)ì€ ì¡´ì¬í•¨ 
- ê·¸ë˜ë„ ìƒë‹¹íˆ í¡ì‚¬í•œ ì½”ë“œë¥¼ ìƒì„±í•¨ 



##### RNN ì‘ìš©

###### Image Captioning

 <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 6.04.42 PM.png" alt="Screen Shot 2021-08-03 at 6.04.42 PM" style="zoom:30%;" />

- CNN : imageë¥¼ ì²˜ë¦¬
- RNN : sequenceë¥¼ ì²˜ë¦¬
  -  CNNì˜ ê²°ê³¼ë¬¼(Classificationì„ í•œ ê²°ê³¼)ë¥¼ ì…ë ¥ê°’ìœ¼ë¡œ ë°›ì•„ì„œ ì–´ë–¤ê±¸ ì¶œë ¥í•˜ëŠ” ë°©ì‹
- CNN + RNN í•˜ë‚˜ì˜ ë‹¨ì¼ ëª¨ë¸ì´ë¼ì„œ backpropagationì€ í•œêº¼ë²ˆì— ì§„í–‰ë¨

 <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-03 at 6.36.37 PM.png" alt="Screen Shot 2021-08-03 at 6.36.37 PM" style="zoom:50%;" />

- ì²˜ìŒì— CNNë¶€ë¶„ ì—ì„œ imageë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ê³  , ë§ˆì§€ë§‰ì— FCë¥¼ softmaxí•˜ì§€ ì•Šê³  4096 dim vector ê·¸ëŒ€ë¡œ ì¶œë ¥í•¨

- Image Captioningì—ì„œëŠ” ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ”ì¼, ì´ë¯¸ì§€ ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” ì¼ì´ ë³‘í–‰í•´ì•¼ë¨
  - ***Example.*** 
    - CNNì´ imageì—ì„œ ë°€ì§‘("straw")ì„ ì¸ì‹í•˜ê³  h0ì˜ stateì— ì˜í–¥ì„ ì£¼ê²Œë¨
    - ê·¸ëŸ¼ h0ì—ì„œ y0ìœ¼ë¡œ ì „ë‹¬ í•  ë•Œ, "straw" ê´€ë ¨ëœ íŠ¹ì • ìˆ˜ì¹˜ê°€ ë†’ì•„ì§€ê²Œë¨
- ë§Œì•½ xë¥¼ 300 ì°¨ì›ìœ¼ë¡œ í‘œí˜„í–ˆìœ¼ë©´, yëŠ” 301ì°¨ì›ì„ ê°€ì§€ê²Œ ë¨ (End Tokenì´ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì—)

-  ì´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” natural language captionì´ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤ (Microsoft COCO dataset)
- í•œê³„ì  : RNNì€ ì „ì²´ imageë¥¼ ë”± í•œë²ˆë§Œ ë³´ê³  ëë‚¨

###### Attention

- ì´ ëª¨ë¸ì€ ì´ë¯¸ì§€ì˜ ë‹¤ì–‘í•œ ë¶€ë¶„ì„ ë³´ë©´ì„œ captionì„ ìƒì„±í•œë‹¤

- Soft Attention for Captioning

    <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 3.31.58 PM.png" alt="Screen Shot 2021-08-05 at 3.31.58 PM" style="zoom:30%;" />

  1. imageë¥¼ CNNì— ë„£ì–´ì£¼ê³  feature gridì„ ì¶”ì¶œí•¨ 

     (feature grid : D ì°¨ì›ì˜ activation map)

  2. feature gridë¥¼ ì²«ë²ˆì§¸ hidden stateë¥¼ ì´ˆê¸°í™”í•˜ëŠ”ë° ì‚¬ìš©ë˜ê³  ì´ë¥¼ í†µí•´ a1ì´ë¼ëŠ” ê±¸ ì¶”ì¶œí•¨

     (a1 : ìœ„ì¹˜ì— ëŒ€í•œ í™•ë¥  ë¶„í¬)

  3. a1ë¥¼ feature gridì™€ ì—°ì‚°ì„ í•´ì„œ weighted featureë¥¼ êµ¬í•˜ê²Œ ë¨ 

     (weighted feature : input ì´ë¯¸ì§€ë¥¼ summerizeí•˜ëŠ” vector)

      <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 3.54.59 PM.png" alt="Screen Shot 2021-08-05 at 3.54.59 PM" style="zoom:30%;" />

     - weighted featureë¥¼ êµ¬í•˜ëŠ” 2ê°€ì§€ ë°©ë²• :

       1. Soft attention 

          - ëª¨ë“  location(grid)ì„ ê³ ë ¤ : <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 3.58.42 PM.png" alt="Screen Shot 2021-08-05 at 3.58.42 PM" style="zoom:20%;" />
          - ì¥ì  : backpropì´ ê°€ëŠ¥í•¨ìœ¼ë¡œ End-to-End í›ˆë ¨ê°€ëŠ¥
          - ë‹¨ì  : ëª¨ë“  gridë¥¼ ê³ ë ¤í•¨ìœ¼ë¡œ Hard attention ë³´ë‹¤ ì—°ì‚°ëŸ‰ì´ ë§ìŒ 

       2. Hard attention 

          - ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” gridë¥¼ ì„ íƒ : 

            ***Example.*** Paê°€ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ë‹¤ë©´ ì´ ìª½ ì˜ì—­ì„ ì„ íƒí•´ì„œ argmaxë¥¼ í†µí•´ ì´ìª½ ì˜ì—­ì˜ feature vectorì˜ ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ê²Œ ë¨

          - ì¥ì  : Soft attentionë³´ë‹¤ ì—°ì‚°ëŸ‰ì´ ì ê³  ì •í™•ë„ê°€ ì¢€ë” ë†’ìŒ 

          - ë‹¨ì  : backpropì´ ì•ˆë˜ì„œ ë³„ë„ì˜ ê°•í™” í•™ìŠµì„ ì‹œì¼œì¤˜ì•¼ ë¨

     - Soft attention :vs: Hard attention 

        <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 4.06.44 PM.png" alt="Screen Shot 2021-08-05 at 4.06.44 PM" style="zoom:35%;" />

       :small_red_triangle: ê´€ì°°Point - ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ë” ì í•©í•œ captioningì„ í•˜ê¸° ìœ„í•´ ë‹¤ìŒì— attentionì„ ì¤„ ë¶€ë¶„ì„ ê²°ì •í•¨

       ğŸ’ğŸ» Soft attention : ëª¨ë“  ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ê³  ëª¨ë“  ìœ„ì¹˜ë“¤ì˜ í™•ë¥ ì„ í‰ê· í–ˆê¸° ë•Œë¬¸ì— diffusioní•œ íš¨ê³¼ê°€ ë‚¨. ì¦‰, í™•ë¥ ë¶„í¬ë¥¼ ì‹œê°í™”í•œ ì…ˆ

       ğŸ’ğŸ» Hard attention : ìµœëŒ€ í™•ë¥ ì„ ë³´ì´ëŠ” í•œêµ°ë° ìœ„ì¹˜ë§Œ ê³ ë ¤í•˜ê¸° ë•Œë¬¸ì— í•œ êµ°ë°ë§Œ ë°ê²Œ ë³´ì„

  4. weighted feature vector, ì²«ë²ˆì§¸ ë‹¨ì–´, ì´ì „ ë‹¨ê³„ì˜ hidden state ê°€ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ h1ì„ ìƒì„±í•˜ê²Œ ë¨

  5. h1ì€ d1ê³¼ a2ë¥¼ outputìœ¼ë¡œ ëƒ„

     (d1 : ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  ë¶„í¬) 

     (a2 : ìœ„ì¹˜ì— ëŒ€í•œ í™•ë¥  ë¶„í¬)

  6. a2ë¥¼ ê°€ì§€ê³  ë‹¤ì‹œ 3. ë¶€í„° ì§„í–‰ë˜ëŠ” ë°˜ë³µ 

- ***Attention ë§¤ì»¤ë‹ˆì¦˜ì˜ í•œê³„ì *** : Fixed gridì— í•œì •ë˜ì–´ì„œ attentionì„ ì£¼ê²Œ ë¨

- ì„ì˜ ì§€ì ì˜ Attentionì„ ì£¼ëŠ” ë°©ë²•ë“¤ :

  1. Graves, â€œGenerating Sequences with Recurrent Neural Networksâ€, arXiv 2013

     - Textë¥¼ ì½ì€ ë‹¤ìŒì— ì‹¤ì œ ì†ê¸€ì”¨ ì²˜ëŸ¼ Textë¥¼ ìƒì„±í•´ì¤Œ

        <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 4.22.32 PM.png" alt="Screen Shot 2021-08-05 at 4.22.32 PM" style="zoom:33%;" />

  2. Gregor et al, â€œDRAW: A Recurrent Neural Network For Image Generationâ€, ICML 2015

     -  inputì— ìˆì–´ì„œ ì„ì˜ ì§€ì ì— Attentionì„ ì£¼ë©´ì„œ image classify ê°€ëŠ¥, outputì— ìˆì–´ì„œë„ ì„ì˜ ì§€ì ì— Attentionì„ ì£¼ë©´ì„œ imageë¥¼ ìƒì„± í•´ëƒ„

         <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 4.28.07 PM.png" alt="Screen Shot 2021-08-05 at 4.28.07 PM" style="zoom:30%;" />

  3. Jaderberg et al, â€œSpatial Transformer Networksâ€, NIPS 2015

     - DRAWì™€ ë¹„ìŠ·í•˜ë©´ì„œ ì¢€ ë” ì²´ê³„í™” ë¨

     - Question : input ì´ë¯¸ì§€ì—ì„œ object localizeë¥¼ í•´ì„œ Boxì— ëŒ€í•œ ì¢Œí‘œê°€ ìƒê¸°ê³  ì´ ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ cropí•˜ê³  rescalingì„ í•˜ëŠ” ê³¼ì •ì„ ë¯¸ë¶„ ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ”ê°€?

       ğŸ¤” outputì˜ pixel ì¢Œí‘œë¥¼ inputì˜ pixel ì¢Œí‘œì— mappingì„ ì‹œì¼œì£¼ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì

        <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 5.17.33 PM.png" alt="Screen Shot 2021-08-05 at 5.17.33 PM" style="zoom:30%;" />

       outputì˜ í•œ ì¢Œí‘œê°€ input ì´ë¯¸ì§€ì— ì–´ë””ì— mapping ë˜ëŠ”ì§€ ì´ê²ƒì„ ì°¾ëŠ” ê³¼ì •ì„ ë°˜ë³µí•¨   

       ìš°ë¦¬ networkëŠ” Î¸ë“¤ì„ ì˜ˆì¸¡í•˜ë©´ì„œ inputì— attentionì„ ì£¼ê²Œë¨ 

       

     - Spatial Transformer Networksì˜ ì „ì²´ ê³¼ì •ì´ ì—°ì†ì ì´ê³  ë¯¸ë¶„ ê°€ëŠ¥í•¨ 

     - ì „ì²´ pipeline

        <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-05 at 4.57.15 PM.png" alt="Screen Shot 2021-08-05 at 4.57.15 PM" style="zoom:40%;" />

       1. Input feature map Uê°€ Localization netì— ë“¤ì–´ê°€ì„œ transformation parameter Î¸ë¥¼ ë½‘ì•„ëƒ„
          - ì´ë•Œ Localization netì˜ êµ¬ì¡°ëŠ” conv. net ì´ë“  FC netì´ë“  ìƒê´€ì—†ì´ ë§ˆì§€ë§‰ì— Regression layerë§Œ ì˜ ë“¤ì–´ê°€ì„œ parameter ì¶”ì¶œë§Œ ì˜í•˜ë©´ ë¨ 
       2. ì•ì—ì„œ ë½‘ì•„ë‚¸ transformation parameter Î¸ëŠ” grid generatorì— ë“¤ì–´ê°€ì„œ sampling ì§€ì ì˜ ìœ„ì¹˜ê°€ ì§€ì •ëœ sampling grid TÎ¸(G) ë¥¼ ìƒì„±í•¨
       3. Samplerì—ëŠ” Input feature map Uì™€ sampling grid TÎ¸(G)ê°€ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°
          -  sampling grid TÎ¸(G)ì—ëŠ” sampling pointê°€ ì°í˜€ìˆê¸° ë•Œë¬¸ì— ê·¸ê²ƒì„ Input feature map Uì— ì ìš©í•˜ë©´ output feature map Vë¥¼ ë½‘ì•„ë‚¼ ìˆ˜ ìˆìŒ

       

     - ê²°ê³¼ë¬¼

         <img src="/assets/images/è®¡è§†/myNote/gif/STN.gif" alt="STN" style="zoom:53%;" />

       - Spatial TransformerëŠ” ë™ì ìœ¼ë¡œ ê°ê°ì— ë§ëŠ” transformationì„ í•´ì¤Œ

       - ì°¨ì›ì´ ê¼¬ì—¬ìˆëŠ” ê²ƒë“¤ì— ëŒ€í•´ì„œ ì…ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì„œ ì œëŒ€ë¡œ ëœ ê²°ê³¼ë¥¼ ë„ì¶œí•¨

       - íšŒì „ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë„ ì˜ ë³µì›ì„ í•´ì¤Œ

       - Spatial Transformerë¥¼ ì˜ ê°–ì¶”ê²Œëœë‹¤ë©´ ì¼ë°˜ì ì¸ Classification Networkì— ì‚½ì…ì„ í•´ì£¼ê³  attentionì„ ì£¼ëŠ” ë²•ì„ í•™ìŠµí•˜ê²Œ í•´ì¤„ìˆ˜ ìˆê²Œ ë¨

         - **spatial invariance** : ì´ë¯¸ì§€ê°€ ë³€í™˜ë˜ì–´ë„ ê·¸ ì´ë¯¸ì§€ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒ. (ex. ê³ ì–‘ì´ë¥¼ 90ë„ íšŒì „ì‹œì¼œë†“ì•„ë„ ê³ ì–‘ì´ë¡œ ì¸ì‹í•˜ëŠ” ëŠ¥ë ¥)

         - ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” **spatial invariance** ê°€ ì¤‘ìš”í•œë° ì¼ë°˜ì ì¸ CNNì—ì„œëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ max pooling layerê°€ í•„ìš”í•¨ 

         - Spartial Transformationì€ max pooling layerë³´ë‹¤ ë” ì¢‹ì€ spatial invariance ëŠ¥ë ¥ì„ ê°–ê²Œ í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ì˜ íŠ¹ì • ë¶€ë¶„ì„ ìë¥´ê³  ë³€í™˜í•´ì„œ ê·¸ ë¶€ë¶„ë§Œ ë–¼ì–´ì„œ íŠ¸ë ˆì´ë‹ì„ ì‹œí‚´

         - ì´ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ *affine transformation*ì´ë¼ê³  í•¨

         - CNN ì•ˆì— í•˜ë‚˜ì˜ layerë¡œ spartial transformation moduleì´ ë“¤ì–´ê°€ëŠ”ë° ì´ layerëŠ” ìœ„ì˜ *affine transformation*ì„ í•˜ëŠ”ë° í•„ìš”í•œ parameterì„ ë°°ì›€

         - CNN ì…ë ¥ ë°”ë¡œ ì•ì— Spatial Transformer Layerë¥¼ ë‘ëŠ” ê²ƒì´ ğŸ‘

           

#### Long Short Term Memory (LSTM)

- RNNì€ ì…ë ¥ squence ***ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´*** ì˜¤ë˜ëœ ë°ì´í„°ë¥¼ ìŠì–´ë²„ë¦¬ëŠ” ì¹˜ëª…ì ì¸ ë‹¨ì ì´ ìˆìŒ 

<img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 11.56.43 AM.png" alt="Screen Shot 2021-08-04 at 11.56.43 AM" style="zoom:50%;" />

- ìœ„ ê·¸ë¦¼ì€ ì…ë ¥ squence ê¸¸ì´ê°€ ì§§ì•„ì„œ ë¬¸ì œëŠ” ì—†ì§€ë§Œ ë§Œì•½ ì…ë ¥ squence ê¸¸ì´ê°€ 100ê°œ ì´ìƒì¼ ê²½ìš° ë‹¤ìŒê³¼ê°™ì€ ë¬¸ì œë“¤ì´ ìƒê¸´ë‹¤

1. **Vanishing Gradient** : 

   backpropagationæ—¶ Gradient (<img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 12.13.24 PM.png" alt="Screen Shot 2021-08-04 at 12.13.24 PM" style="zoom:25%;" />)ê°€ 0ì— ê·¼ì ‘í•˜ë©´ ìƒˆë¡œ ì—…ë°ì´íŠ¸ ë˜ëŠ” WeightëŠ” ê¸°ì¡´ì˜ Weightì™€ ë³„ ì°¨ì´ê°€ ì—†ì–´ì§ ğŸ’ğŸ»  ì¦‰, í•™ìŠµì‹œê°„ì´ ê¸¸ì–´ì§€ê³  ë¹„íš¨ìœ¨ì ì„

2. **Exploding Gradient**

   backpropagationæ—¶ Gradient (<img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 12.13.24 PM.png" alt="Screen Shot 2021-08-04 at 12.13.24 PM" style="zoom:25%;" />)ê°€ ë§¤ìš° í° ìˆ˜ê°€ ë˜ì–´ ìƒˆë¡œ ì—…ë°ì´íŠ¸ ë˜ëŠ” WeightëŠ” ê¸°ì¡´ì˜ Weightì™€ ë§¤ìš° ë‹¤ë¥´ê²Œ ì—…ë°ì´íŠ¸ë¨ ğŸ’ğŸ»  ì¦‰, ì´í›„ Weightì˜ ì—…ë°ì´íŠ¸ì˜ ë³€í™”ê°€ ì»¤ì§€ë©´ì„œ í›ˆë ¨ì´ ìˆ˜ë ´ë˜ì§€ ëª»í•¨

- LSTMì€ ê¸°ì¡´ RNNì˜ hidden state ì´ì™¸ì—ë„ ë³„ë„ì˜ cell stateë¼ëŠ” ë³€ìˆ˜(variable)ë¥¼ ë‘ì–´, ê·¸ ê¸°ì–µë ¥ì„ ì¦ê°€ì‹œì¼°ì„ ë¿ë§Œ ì•„ë‹ˆë¼, ì—¬ëŸ¬ê°€ì§€ ê²Œì´íŠ¸(gate)ë¥¼ ë‘ì–´ ê¸°ì–µí•˜ê±°ë‚˜, ìŠì–´ë²„ë¦¬ê±°ë‚˜, ì¶œë ¥í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ì˜ ì–‘ì„ ìƒí™©ì— ë”°ë¼ì„œ, ë§ˆì¹˜ ìˆ˜ë„ê¼­ì§€ë¥¼ ì ê¶œë‹¤ ì—´ë“¯ì´, íš¨ê³¼ì ìœ¼ë¡œ ì œì–´í•˜ì—¬ ê¸´ ê¸¸ì´ì˜ ë°ì´í„°ì— ëŒ€í•´ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŒ

 <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 12.27.51 PM.png" alt="Screen Shot 2021-08-04 at 12.27.51 PM" style="zoom:40%;" />

- <span style="color:orange">í˜„ì¬ì˜ cell state</span> êµ¬í•˜ê¸° :
  - ***f*** : <span style="color:orange">í˜„ì¬ì˜ cell state</span>ê°€ ë°”ë¡œ ê·¸ ì „ì˜ cell stateë¥¼ ì–¼ë§ˆë‚˜ ìŠì„ ê²ƒì´ëƒ ë¥¼ ì •í•´ì£¼ëŠ” ê²ƒ
  - ***g*** : input ê°’ì„ <span style="color:orange">í˜„ì¬ì˜ cell state</span>ì— ì–¼ë§ˆë‚˜ ë”í•´ì£¼ê±°ë‚˜ ë¹¼ì¤„ ê²ƒì´ëƒ ë¥¼ ì •í•´ì£¼ëŠ” ê²ƒ
- <span style="color:green">í˜„ì¬ì˜ hidden state</span> êµ¬í•˜ê¸° :
  - <span style="color:orange">í˜„ì¬ì˜ cell state</span>ì— tanhë¥¼ ì·¨í•´ì¤€ ë‹¤ìŒ ***o***ë¥¼ ê³±í•´ì¤Œ
  - ***o*** : <span style="color:orange">í˜„ì¬ì˜ cell state</span> ì¤‘ì— ì–´ëŠ ë¶€ë¶„ì„ ë‹¤ìŒì˜ hidden cellë¡œ ì „ë‹¬í•  ì§€ ê²°ì •í•˜ëŠ” ê²ƒ

- LSTMëŠ” vanishing gradient ë¬¸ì œë¥¼ í•´ê²°í•¨?
  - LSTM ***doesnâ€™t guarantee*** that there is no vanishing/exploding gradient
    - but it does provide an easier way for the model to learn long-distance dependencies

- LSTMì˜ í™•ì¥íŒ  : Gated Recurrent Unit (GRU)

   <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 1.32.23 PM.png" alt="Screen Shot 2021-08-04 at 1.32.23 PM" style="zoom:45%;" />

  - LSTM ì…€ì˜ ê°„ì†Œí™”ëœ ë²„ì „

  - ë‘ ìƒíƒœ ë²¡í„° cell state ì™€ hidden stateê°€ í•˜ë‚˜ì˜ hidden state vectorë¡œ í•©ì³ì§

  - í•˜ë‚˜ì˜ gate controllerì¸ ***z***ê°€ **forget**ê³¼ **input** gateë¥¼ ëª¨ë‘ ì œì–´í•¨ 

  - GRU cellì€ output gateê°€ ì—†ì–´ ì „ì²´ state vectorê°€ time stepë§ˆë‹¤ ì¶œë ¥ë˜ë©°, ì´ì „ hidden state vectorì˜ ì–´ëŠ ë¶€ë¶„ì´ ì¶œë ¥ë ì§€ ì œì–´í•˜ëŠ” ìƒˆë¡œìš´ gate controllerì¸ ***r*** ì´ ìˆìŒ

    

***

ã€ŠReferenceã€‹

1.  <a href="https://www.youtube.com/watch?v=5t1E3LZ3FDY&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=6">Youtube</a>
2. <a href="https://cs231n.github.io/">Course Site</a>
3. <a href="https://kh-kim.gitbooks.io/pytorch-natural-language-understanding/content/sequential-modeling/lstm.html">Gitbook - LSTM</a>
4. <a href="https://www.youtube.com/watch?v=bX6GLbpw-A4">YoutubeÂ -Â LSTM</a>

***

