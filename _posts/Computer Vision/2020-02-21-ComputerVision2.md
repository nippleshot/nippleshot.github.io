---
layout: article
title: 02. CS231N ìš”ì•½ (CNN)
author: J_å®‹
tags: ComputerVision CS231n í•œê¸€
mathjax: true
key: ComputerVision02
---



#### Convolutional Neural Network

##### CNNì˜ ì†Œê°œ

- ê°„ëµí•œ ì—­ì‚¬ : <a href="https://youtu.be/5t1E3LZ3FDY?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&t=2139">Youtube</a>
- Terminology
  - Localization : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ë‚´ì—ì„œ í•˜ë‚˜ì˜ Objectë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒ
  - Detection : í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ë‚´ì—ì„œ ì—¬ëŸ¬ê°œì˜ Objectë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒ
  - Segmentation : Objectì˜ í˜•íƒœë¥¼ ë”°ë‚´ëŠ” ê²ƒ



##### CNN architecture

<img src="/assets/images/è®¡è§†/myNote/pic02/cnn_architectures-03.png" alt="cnn_architectures-03" style="zoom:50%;" />

##### Convolution Layer

- ë™ì‘ ê³¼ì • ë° ì„¤ëª… (ğŸ‘‡ Stride = 2, Padding = 1æ—¶)

  <img src="/assets/images/è®¡è§†/myNote/gif/CNN.gif" alt="CNN" style="zoom:100%;" />

  - Filter

    - ë°˜ë“œì‹œ inputê³¼ ê°™ì€ depthë¥¼ ê°€ì ¸ì•¼ë¨

    - ê°„ë‹¨íˆ ì„¤ëª…í•˜ìë©´ Filterì˜ ì—­í• ì€ feature ì‹ë³„ìš©ì„

       <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-30 at 2.01.40 PM.png" alt="Screen Shot 2021-07-30 at 2.01.40 PM" style="zoom:30%;" />

  - Convolution operation

    - filterê°€ image(= Input volume) ìœ„ë¡œ ì´ë™í•˜ë©´ì„œ, dot product ê³„ì‚°

  - Convolution Layerì—ì„œëŠ” *x*ê°œì˜ filter ê°€ Convolution Layerì˜ inputìœ„ì—ì„œ Convolution operationë¥¼ ì§„í–‰í•˜ë©´ *x*ê°œì˜ Activation mapë“¤ì„ ìƒì„±í•¨

    <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-04 at 1.02.10 PM.png" alt="Screen Shot 2021-08-04 at 1.02.10 PM" style="zoom:40%;" />

    - ì°¸ê³  : Filterê°€ 1 Ã— 1 Ã— input depth ì´ë¼ë„ ì˜ë¯¸ê°€ ìˆìŒ 

       <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n18-13screenshot.png" alt="cs231n18-13screenshot" style="zoom:25%;" />

      - But Inputì´ 2ì°¨ì› ( ex. 6Ã—6Ã—1 )  ì¼ ê²½ìš° stride 1ë¡œ 1Ã—1Ã—1 ì¸ Filter ì·¨í•˜ëŠ”ê±´ ì•„ë¬´ëŸ° ì˜ë¯¸ ì—†ìŒ

         <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-30 at 2.09.16 PM.png" alt="Screen Shot 2021-07-30 at 2.09.16 PM" style="zoom:30%;" />

    - Zero-Padding

      - Zero-Paddingë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ Activation mapì´ ëª‡ê°œì˜ layer ë§Œ ê±°ì¹˜ê²Œ ë˜ë©´ sizeê°€ 0ìœ¼ë¡œ ì†Œë©¸ë¨
      - Zero-Paddingë¥¼ ì‚¬ìš©í•˜ì—¬  Activation map í¬ê¸°ë¥¼ ë³´ì¡´í•´ì£¼ë˜ ê·¸ë˜ë„ sizeë¥¼ ì ì°¨ ì¤„ì—¬ì£¼ê¸° ìœ„í•´ pooling layerê°€ í•„ìš”
      - *è®¡ç®—å…¬å¼1* ï¼š ì í•©í•œ Zero-Padding ìˆ˜ êµ¬í•˜ê¸°

      $$
      {\text{ Filter Width or Height size } - 1 \over 2 }
      $$

    - ìƒì„±ëœ Activation mapë“¤ì€ ë‹¤ìŒ Convolution Layerì˜ inputìœ¼ë¡œ ì „ë‹¬ë¨

      - *è®¡ç®—å…¬å¼2* ï¼š1ê°œ Activation mapì˜ Width or Height size êµ¬í•˜ê¸°

        :warning: total Activation map depth  = filter ê°œìˆ˜

      $$
      {\text{ Input Width or Height size } - \text{ Filter Width or Height size } \over \text{ Stride }} + 1
      $$

    - ***Example*** : <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n15-48screenshot.png" alt="cs231n15-48screenshot" style="zoom:23%;" />

      *Q1 : ê·¸ëŸ¼ Activation map sizeëŠ”?*

      
      $$
      \text{ Input size (with pad)} = 36 \times 36 \times 3 \\
      \text{ 1 Activation map size } = {36 - 5 \over 1} + 1 = 32 \\
      \text{ Total Activation map size } = 32 \times 32 \times \color{red}{10}
      $$
      

      *Q2 : ì´ layerì˜ parameterìˆ˜ëŠ” ?*

      
      $$
      \text{ Amount of 1 Filter's parameter (with bias)} = (5 \times 5 \times 3 ) + 1 = 76 \\
      \text{ Total amount of 10 Filter's parameter (with bias)} = 76 \times 10 = 760
      $$

##### Pooling Layer

- ê° Activation mapì„ ì¢€ ë” ì‘ê²Œ, ì¢€ ë” ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì£¼ëŠ” ì—­í• 

   <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n23-52screenshot.png" alt="cs231n23-52screenshot" style="zoom:33%;" />

- Pooling ë°©ë²• :

  æ–¹æ³•1 ï¼š**Max Pooling** : 

  - Hyperparameters : 
    - Filter size (ì¼ë°˜ì ìœ¼ë¡  2 ì„¤ì •)
    - Stride (ì¼ë°˜ì ìœ¼ë¡  2 ì„¤ì •)

   <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n26-3screenshot.png" alt="cs231n26-3screenshot" style="zoom:25%;" />

  - *è®¡ç®—å…¬å¼3* ï¼šMax Poolingí†µí•´ ë‚˜ì˜¨ Activation mapì˜ Width or Height size êµ¬í•˜ê¸°

    :warning: total Activation map depth = Input depth

    
    $$
    {\text{ Input Width or Height size } - \text{ Filter Width or Height size } \over \text{ Stride }} + 1
    $$

##### Classification Layer

- Flattened Layer
  - used to convert the n-dimensional vector into a mono-dimensional vector

- Fully Connected Layer
  - compute the class scores
  - resulting a vector, where each of the numbers correspond to a class score



#### CNN Case Study

##### LeNet-5 (LeCun at al. 1998)

 <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n31-48screenshot.png" alt="cs231n31-48screenshot" style="zoom:50%;" />

- Detail : <a href="https://blog.naver.com/laonple/220648539191">Blog</a>



##### AlexNet (Krizhevsky et al. 2012)

 <img src="/assets/images/è®¡è§†/myNote/pic02/AlexNet-1.png" alt="AlexNet-1" style="zoom:67%;" />

- input size : 227Ã—227Ã—3

- 2ê°œì˜ GPUë¡œ ë³‘ë ¬ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œ ë³‘ë ¬ì ì¸ êµ¬ì¡°ë¡œ ì„¤ê³„ë¨

- ì²«ë²ˆì§¸ Layer : Convolution Layer

  -  96ê°œì˜ 11x11x3 ì‚¬ì´ì¦ˆ Filterë¡œ inputì„ Convolution operation í•´ì¤Œ, Stride=4
    - ì¦‰, parameter ê°œìˆ˜ = (11x11x3) x 96 = 34,848 
    - ë³‘ë ¬ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´  Filterë¥¼ 48ê°œ 48ê°œë¡œ ë‚˜ëˆ”

- ë‘ë²ˆì§¸ Layer : Pooling Layer

  - 3x3 ì‚¬ì´ì¦ˆ Filter, Stride=2 ì ìš©
  - parameter ê°œìˆ˜ = 0, (**parameterëŠ”  Convolution Layerë•Œë§Œ ìˆëŠ” ê²ƒ!**)

- ì „ì²´ Layer êµ¬ì¡° :

   <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-30 at 3.28.05 PM.png" alt="Screen Shot 2021-07-30 at 3.28.05 PM" style="zoom:25%;" />

  -  í†µìš©ì ìœ¼ë¡œ Classifier ì§ì „ì— ìˆëŠ” Fully Connected Layerë¥¼ "<span style="color:orange">FC7</span>" ë¼ê³ ë„ í•œë‹¤ 
  - :warning: <span style="color:green">Normalization Layer</span> : ì§€ê¸ˆì€ íš¨ìš©ì´ ë³„ë¡œ ì—†ì–´ì„œ ë”ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•¨

- íŠ¹ì§• :

  - ìµœì´ˆë¡œ ReLUë¥¼ ì‚¬ìš©í•œ ëª¨ë¸
  - Data augmentationì„ ë§ì´ ì‚¬ìš©í•¨ 
  - Fully Connected Layerì—ì„œ Dropout = 0.5 
  - Batch size = 128
  - 7ê°€ì§€ CNN ëª¨ë¸ì„ ì•™ìƒë¸”í•´ì„œ error rateë¥¼ 2.8%ì •ë„ ì¤„ì˜€ìŒ
  - Learning rate = 0.01 (1e-2)



##### ZFNet (Zeiler and Fergus, 2013)

- AlexNetê³¼ ìœ ì‚¬

   <img src="/assets/images/è®¡è§†/myNote/pic02/remotesensing-12-01667-g005 copy.png" alt="remotesensing-12-01667-g005 copy" style="zoom:20%;" />

  - ëŒ€ì‹  ì²«ë²ˆì§¸ Layerì˜ 11x11 Filter, Stride=4 ë¥¼ 7x7 Filter, Stride=2ë¡œ ì¤„ì„
  - 3,4,5ë²ˆì¬  Layerì˜ Filter ê°œìˆ˜ë¥¼ ëŠ˜ë¦¼

- Detail : <a href="https://blog.naver.com/laonple/220673615573">Blog</a>



##### VGGNet (Simonyan and Zisserman, 2014)

 <img src="/assets/images/è®¡è§†/myNote/pic02/clip_image001.png" alt="clip_image001" style="zoom: 50%;" />

- ëª¨ë“  Convolution Layerì—ëŠ” ì˜¤ì§ 3x3 Filter , Stride=1, Padding=1ë¥¼ ì‚¬ìš©
- ëª¨ë“  Max Pooling Layerì—ëŠ” ì˜¤ì§ 2x2 Filter , Stride=2 ë¥¼ ì‚¬ìš©

- ì „ì²´ Layer 

  <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n 41-0screenshot.png" alt="cs231n 41-0screenshot" style="zoom:50%;" />

  - ìœ„ì—ì„œ ë³´ì´ë“¯ì´ Fully Connectedë¥¼ ì‚¬ìš©í•˜ëŠ” ê±´ íš¨ìœ¨ì ì´ì§€ ëª»í•´ average poolingë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ

     <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-30 at 4.07.16 PM.png" alt="Screen Shot 2021-07-30 at 4.07.16 PM" style="zoom:23%;" />



##### GoogLeNet  (Szegedy et al. 2014)

<img src="/assets/images/è®¡è§†/myNote/pic02/35002702-d5dccb60-fb2d-11e7-88ac-e29d0319f32b.png" alt="35002702-d5dccb60-fb2d-11e7-88ac-e29d0319f32b" style="zoom:50%;" />

- Inception ëª¨ë“ˆì´ ì—°ì†ì ìœ¼ë¡œ ì—°ê²°ëœ í˜•íƒœ 

  - Inception module

     <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n41-59screenshot.png" alt="cs231n41-59screenshot" style="zoom:43%;" />

- Fully Connected Layerë¥¼ ì•„ì˜ˆ ì œê±°í•˜ê³  average poolingì„ ì‚¬ìš©í•¨

  - ëª¨ë¸ì˜ Parameter ìˆ˜ë¥¼ ë‹¤ í•©ì¹˜ë©´ ì•½ 500ë§Œê°œ ë°–ì— ì•ˆë¨!

- AlexNetê³¼ ë¹„êµí–ˆì„ ë•Œ,

  - GoogLeNet ì€ AlexNetì˜ 1/12 ìˆ˜ì¤€ì˜ parameterë¥¼ ê°€ì§
  - ì—°ì‚°ì€ 2ë°°ì´ìƒ ë¹ ë¦„
  - Top-5 ErrorëŠ” ì•½ 10% ê°ì†Œë¨ 



##### ResNet (He et al. 2015)

- ëª¨ë¸ë“¤ì˜ ë°œì „

   <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n45-1screenshot.png" alt="cs231n45-1screenshot" style="zoom:40%;" />

  - Error rateëŠ” ì ì  :arrow_heading_down: , Layerì˜ í¬ê¸°ëŠ” :arrow_heading_up:



- ResNetì˜ ì£¼ì¥

  <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n45-58screenshot.png" alt="cs231n45-58screenshot" style="zoom:50%;" />

  - ê¸°ì¡´ì˜ Netë“¤ì€ Layerê°€ ë§ì•„ì§ì— ë”°ë¼ Error rateê°€ ì»¤ì§€ëŠ” í˜„ìƒì´ ë‚˜ì˜´ìœ¼ë¡œì¨ ìµœì í™”ì— ì‹¤íŒ¨í•´ ìˆë‹¤ê³  í•¨
  - ResNetì˜ ê²½ìš° Layerê°€ ë§ì•„ì§ì— ë”°ë¼ Error rateëŠ” ì¤„ì–´ë“¬ 



- íŠ¹ì§•

  - 8ê°œì˜ GPU machineì—ì„œ 2-3ì£¼ ë™ì•ˆ trainì„ ì‹œí‚´

  - test (runtime) í•  ë•ŒëŠ” ë¹„ë¡ VGGNet ë³´ë‹¤ 8ë°° ë” ë§ì€ Layerë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ ì„±ëŠ¥ì€ ë” ë¹ ë¦„. How?

    - ì²«ë²ˆì§¸ Convolution Layerë‹¤ìŒ ë°”ë¡œ Poolingì„ í†µí•´ sizeë¥¼ 56x56ìœ¼ë¡œ ì¤„ì—¬ ì´í›„ 150ê°œ Layerë“¤ì€ ì´ size ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰ë¨

    - Skip Connection

      <img src="/assets/images/è®¡è§†/myNote/pic02/cs231n47-43screenshot.png" alt="cs231n47-43screenshot" style="zoom:50%;" />

      - Plue ì—°ì‚°ì„ ì¶”ê°€í•´ì„œ Backpropagationì´ ì§„í–‰ë  ë•Œ, ê³¼ì •ì„ ê±´ë„ˆë›°ê³  ì•ìª½ Convolution Layerë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆìŒ

         :warning: å‚è€ƒ ï¼š <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-31 at 10.24.45 AM.png" alt="Screen Shot 2021-07-31 at 10.24.45 AM" style="zoom:30%;" />

  - ëª¨ë“  Convolution Layer ë‹¤ìŒ Batch Normalizationì„ ì‚¬ìš©í•¨

  - Xavier/2 Weight Initializationì„ ì‚¬ìš©í•¨ (He et al. ì´ ë§Œë“ ê±°ì„)

  - Learning rate = 0.1,  validation set errorê°€ ì •ì²´ ë˜ë©´ 10ìœ¼ë¡œ ë‚˜ëˆ´ìŒ

  - dropoutì„ ì•„ì˜ˆ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ 



##### DeepMind's AlphaGo

<img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-07-30 at 4.51.14 PM.png" alt="Screen Shot 2021-07-30 at 4.51.14 PM" style="zoom:50%;" />

- Input size : 19x19x48
- Output size : 19x19 (19x19 ì¸ ë°”ë‘‘íŒì˜ ì–´ë””ì— ë‘ì–´ì•¼í•˜ëŠ”ì§€ì— ëŒ€í•œ í™•ë¥ )



#### ìµœê·¼ Trend

- ë” ì‘ì€ Filter ì‚¬ìš©
- ë” ê¹Šì€ Layerì˜ architecure ì‚¬ìš©
- Pooling Layer, Fully Connected Layerë¥¼ ì ì°¨ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
  - ê·¸ëƒ¥ Convolution Layerë§Œ ì‚¬ìš© : Strideë¥¼ í™œìš©í•˜ì—¬ spacial reductioní•˜ëŠ” ë°©ì‹ìœ¼ë¡œ
  -  Fully Connected Layerì˜ ë¬¸ì œì  :
    1. ì—°ì‚°ëŸ‰ ë§¤ìš° ë§ìŒ
    2. classificationì— ì˜í–¥ì„ ë¼ì¹œ featureê°€ ì–´ëŠ ë¶€ë¶„ì—ì„œ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ (ìœ„ì¹˜ ì •ë³´) ë„ ì•Œ ìˆ˜ ì—†ìŒ
    3. input ì˜ í¬ê¸° ë˜í•œ ì œí•œëœë‹¤

##### Global Average Pooling (GAP)

- Fully Connected Layerì˜ ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œëœ ê²ƒ

  <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-01 at 9.22.52 PM.png" alt="Screen Shot 2021-08-01 at 9.22.52 PM" style="zoom:50%;" />

  - GAPëŠ” ê°ê°ì˜ feature map(= Activation map)ì—ì„œ ëŒ€í‘œê°’(average)ì„ ì¶”ì¶œí•´ ë°”ë¡œ ê° classì— ëŒ€í•œ scoreë¡œ êµ¬ì„±ëœ vectorë¡œ ë‚˜íƒ€ë‚¨

    <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-01 at 9.18.51 PM.png" alt="Screen Shot 2021-08-01 at 9.18.51 PM" style="zoom:35%;" />

- GAPì˜ íŠ¹ì§• :
  - ì´ì „ feature mapë“¤ì´ ê°€ì§€ê³  ìˆëŠ” ìœ„ì¹˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ class categoryë¡œ ì§ì ‘ ì—°ê´€ì‹œí‚¤ëŠ” ì—­í• 
  - ë³„ë„ì˜ parameter optimization ì„ í•„ìš”ë¡œ í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì—°ì‚°ëŸ‰ì´ ì ìŒ
    - overfitting ë¬¸ì œë„ ì°¨ë‹¨í•  ìˆ˜ ìˆìŒ



#### Adversarial examples

- Input ì´ë¯¸ì§€ì— ëŒ€í•œ ìµœì í™”ë¥¼ í•¨ìœ¼ë¡œì¨ ìš°ë¦¬ëŠ” ì–´ë–¤ Classì— Scoreë¼ë„ maximizeí•  ìˆ˜ ìˆìŒ

  - ì´ëŸ° ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ CNNë¥¼ ì†ì¼ ìˆ˜ ë„ ìˆìŒ 

     <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-02 at 4.58.25 PM.png" alt="Screen Shot 2021-08-02 at 4.58.25 PM" style="zoom:30%;" />

- EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES [Goodfellow, Shlens & Szegedy, 2014]

  - "Neural Networkì´ Adversarial attackì— ì·¨ì•½í•œ ê²ƒì€ Linear í•œ ì„±ì§ˆ ë•Œë¬¸ì´ë‹¤"

    ***Example.*** Binary linear classifierë¥¼ ì†ì—¬ë³´ê¸°

     <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-02 at 5.04.18 PM.png" alt="Screen Shot 2021-08-02 at 5.04.18 PM" style="zoom:40%;" />

    â€‹	ğŸ‘‰ class 1ê³¼ class 0ì˜ í™•ë¥ ì„ í•©í•˜ë©´ 1.0 ì´ ë‚˜ì˜´, ê·¸ë˜ì„œ class 1 í™•ë¥  = 1.0 - class 0ì˜ í™•ë¥ 

     <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-02 at 5.06.55 PM.png" alt="Screen Shot 2021-08-02 at 5.06.55 PM" style="zoom:30%;" />

    ğŸ’ğŸ» ì´ì œ Adversarialí•œ xë¥¼ ë§Œë“¤ì–´ë³´ì (ì¦‰ ê²°ê³¼ê°€ classifierê°€ class 1ì´ ë‚˜ì˜¤ë„ë¡ xë¥¼ ì¡°ì •í•´ë³´ì)

    - ëŒ€ì‘í•˜ëŠ” wê°€ ì–‘ìˆ˜ ì¼ ê²½ìš° xë¥¼ í¬ê²Œ ë§Œë“¤ê³ , wê°€ ìŒìˆ˜ ì¼ ê²½ìš° xë¥¼ ì‘ê²Œ ë§Œë“¤ì

      - ëŒ€ì‹  Adversarialí•œ xë¥¼ ì›ë˜ xì™€ ìœ ì‚¬í•˜ê²Œ ë³´ì—¬ì•¼ë˜ê¸° ë•Œë¬¸ì— ì•½ê°„ì˜ ë³€í˜•ë§Œ ì¤€ë‹¤ (í•œ 0.5ì •ë„)

       <img src="/assets/images/è®¡è§†/myNote/pic02/Screen Shot 2021-08-02 at 5.12.46 PM.png" alt="Screen Shot 2021-08-02 at 5.12.46 PM" style="zoom:30%;" />

  

- image *x* ê°™ì€ ê²½ìš° í° ì°¨ì›(ex. 224x224)ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë” ì•½ê°„ì˜ ë³€í™”ë§Œ ì£¼ë”ë¼ë„ ë§¤ìš° ì‰½ê²Œ Adversarialí•œ *x*ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŒ

  - ê·¸ë˜ì„œ Linear regressionì€ ì–´ë–¤ ë³€í™”ë¥¼ ì¤˜ì•¼í•˜ëŠ”ì§€ ì •í™•íˆ íŒŒì•…í•˜ê³  ìˆëŠ” ê²½ìš°ë¼ë©´ ì•„ì£¼ ì‘ì€ ë³€í™”ë¼ë„ í¬ê²Œ ë³€ê²½ì„ ì‹œí‚¬ ìˆ˜ ìˆìŒ

- ì‚¬ì‹¤ ì´ëŸ° ë¬¸ì œë“¤ì€ imageì—ì„œë§Œ êµ­í•œë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, speak recognition ë“± ì—¬ëŸ¬ ë°©ë©´ë“¤ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆìŒ



#### Data Augmentation

- ë°ì´í„°ì˜ labelì€ ë³€í•¨ì—†ì´ Pixelì„ ê³ ì¹¨ ê·¸ë¦¬ê³  ì´ ë³€ê²½ëœ ë°ì´í„°ë¥¼ í•™ìŠµí•¨ 

- ë°©ë²•ë“¤ :

1. ë°˜ëŒ€ë¡œ filpí•˜ëŠ” ë°©ë²•

2. ëœë¤í•˜ê²Œ ìë¥´ê³  ìŠ¤ì¼€ì¼ë„ ë‹¤ì–‘í•˜ê²Œ í•˜ëŠ” ë°©ë²•

3. ìƒ‰ì„ jittering í•˜ê¸°

   - ë³µì¡í•œ ë°©ë²• :

     [1] ì´ë¯¸ì§€ì˜ R,G,Bì— ëŒ€í•´ <a href="https://excelsior-cjh.tistory.com/167">PCA</a>ë¥¼ ì ìš©í•¨ 

     [2] ê·¸ëŸ¼ ê° R,G,Bì— ëŒ€í•´ì„œ Principal componet direction (colorê°€ ë³€í™”í•´ ë‚˜ê°€ëŠ” ë°©í–¥ì„±)ì„ ë”°ë¼ì„œ colorì˜ offsetì„ sampling í•´ì¤Œ

     [3] ì´ offsetì„ ëª¨ë“  pixelì— ë”í•´ì¤Œ

and more ...

- ì‘ì€ ë°ì´í„°ì…‹ì˜ ê²½ìš° ë§¤ìš° ìœ ìš©



#### All About Convolutions

##### Small Filter

ë‹¤ìŒ ë°©ì‹ë“¤ì„ í™œìš©í•˜ë©´ CNNì˜ parameter ìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ ì—°ì‚°ëŸ‰ì´ ì¤„ê³  CNNê°€ ë” non-linearityí•˜ê²Œ ë¨ 

1. ***í° filter ì‚¬ìš©ì„ í”¼í•˜ê³  ì‘ì€ filterë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´í•˜ì*** 

   <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 4.27.54 PM.png" alt="Screen Shot 2021-08-04 at 4.27.54 PM" style="zoom:30%;" />

   - 3ê°œì˜ conv. layerê°€ ìˆê³  ê° layerì—ëŠ” 3x3 filter (stride=1)ë¥¼ ì‚¬ìš©í•œë‹¤í•˜ì

   - ì§ê´€ì ìœ¼ë¡œ ë´¤ì„ ë•Œ, 3ë²ˆì§¸ conv. layerì„ í†µê³¼í•œ Activation mapì˜ í•œ ë‰´ëŸ°ì€ input layerì˜ 7x7 ì˜ì—­ (Receptive field) ì„ ë³´ê²Œë˜ëŠ” ì…ˆì„

     - ì¦‰, 7x7 filter (stride=1)ë¥¼ ì§€ë‹Œ conv. layer 1ê°œë¥¼ í†µê³¼ ì‹œí‚¨ ê²ƒê³¼ ê°™ì€ ì˜í–¥ì„ ë³´ì´ëŠ” ì…ˆì´ë‹¤

        <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 4.37.41 PM.png" alt="Screen Shot 2021-08-04 at 4.37.41 PM" style="zoom:30%;" />

   - ê·¸ëŸ¼ ìœ„ì— ë‘ ìƒí™©ì—ì„œ parameter ìˆ˜ëŸ‰ê³¼ ì—°ì‚°íšŸìˆ˜ë¥¼ ê³„ì‚°í•´ë³´ë©´ ì‘ì€ filterë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ë‘ ë°©ë©´ ëª¨ë‘ ë”  ì ë‹¤ëŠ” ê±¸ ì•Œ ìˆ˜ ìˆë‹¤. 

      <img src="/assets/images/è®¡è§†/myNote/pic04/21-57screenshot.png" alt="cs231n 11á„€á…¡á†¼ CNNs in practice 21-57 screenshot" style="zoom:25%;" />

   - ê·¸ë¦¬ê³  ë” ì¸µì„ ìŒ“ì„ ìˆ˜ë¡œ ê·¸ë§Œí¼ activation functionë„ ìŒ“ì•„ì§€ê¸° ë•Œë¬¸ì— non-linearityê°€ ë” ê°•í™”ëœë‹¤

2. ***1x1 "bottleneck" convolutionë„ ë§¤ìš° íš¨ê³¼ì ì„***

    <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 4.58.21 PM.png" alt="Screen Shot 2021-08-04 at 4.58.21 PM" style="zoom:30%;" />

   - Parameter ìˆ˜ëŸ‰ ê³„ì‚° (bias ì œì™¸)

     |                            | Bottleneck       |                      | Single      |
     | -------------------------- | ---------------- | -------------------- | ----------- |
     | **C/2ê°œ 1x1xC filter **    | 1xCx(C/2) ê°œ     | **Cê°œ 3x3xC filter** | 9xCxC ê°œ    |
     | **C/2ê°œ 3x3x(C/2) filter** | 9x(C/2)x(C/2) ê°œ |                      |             |
     | **Cê°œ 1x1x(C/2) filter **  | 1x(C/2)x(C) ê°œ   |                      |             |
     | **Total (Sum)**            | *3.25 x (C^2)*   | **Total (Sum)**      | *9 x (C^2)* |

     ğŸ’ğŸ» ì¦‰ Bottleneck ëª¨ë¸ì˜ Parameter ìˆ˜ëŸ‰ì´ ë” ì ê³  ì´ë¡œ ì¸í•´ ì—°ì‚°ëŸ‰ë„ ë” ì ì„ ê²ƒì„! (+ ë” ê¹Šì€ ì¸µìœ¼ë¡œ ì¸í•œ non-linearity ê°•í™”)

3. ***NxN convolutionì˜ ê²½ìš° 1xN ê·¸ë¦¬ê³  Nx1ì˜ ë‘ ê°œì˜ layerë¡œ ë‚˜ëˆ„ì***

     <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 5.13.46 PM.png" alt="Screen Shot 2021-08-04 at 5.13.46 PM" style="zoom:30%;" />

   ğŸ’ğŸ» ìœ„ì—ì„œ ë³´ì´ë‹¤ ì‹¶ì´ Parameter ìˆ˜ëŸ‰ì´ ë” ì ì–´ì ¸ ì—°ì‚°ì´ ê°€ë²¼ì›Œì§ (+ ë” ê¹Šì€ ì¸µìœ¼ë¡œ ì¸í•œ non-linearity ê°•í™”)

     

- ì‚¬ìš©ëœ ì‚¬ë¡€ : GoogLeNet

   <img src="/assets/images/è®¡è§†/myNote/pic04/Screen Shot 2021-08-04 at 5.16.12 PM.png" alt="Screen Shot 2021-08-04 at 5.16.12 PM" style="zoom:40%;" />



##### Computing Convolutions

###### im2col

- ë‹¤ì°¨ì›ì˜ ë°ì´í„°ë¥¼ í–‰ë ¬ë¡œ ë³€í™˜í•˜ì—¬ í–‰ë ¬ ì—°ì‚°ì„ í•˜ë„ë¡ í•´ì£¼ëŠ” í•¨ìˆ˜

- ë‹¤ì°¨ì› ë°ì´í„°ì˜ í•©ì„±ê³±(convolution) ê²°ê³¼ ==  im2colì„ í†µí•´ í–‰ë ¬ë¡œ ë³€í™˜ëœ ë°ì´í„°ì˜ ë‚´ì  ê²°ê³¼

  1. ì…ë ¥ ë°ì´í„°(4x4x3)ë¥¼ í–‰ë ¬ë¡œ ë³€í™˜ 

   <img src="/assets/images/è®¡è§†/myNote/gif/im2col.gif" alt="im2col" style="zoom:40%;" />

  2. 2ê°œ filter(2x2x3)ë„ í–‰ë ¬ë¡œ ë³€í™˜

   <img src="/assets/images/è®¡è§†/myNote/pic04/im2col2.png" alt="im2col2" style="zoom:43%;" />

  3. ë³€í™˜í•œ ë‘ í–‰ë ¬ì˜ ê³±

   <img src="/assets/images/è®¡è§†/myNote/gif/im2colMul.gif" alt="im2colMul" style="zoom:60%;" />

  4. í–‰ë ¬ë¡œ ë³€í™˜í•œ ì…ë ¥ ë°ì´í„°ì™€ í•„í„°ì˜ í–‰ë ¬ ì—°ì‚° ì´í›„, ìš°ë¦¬ëŠ” ì¶œë ¥ëœ ë°ì´í„°(í–‰ë ¬)ë¥¼ ë‹¤ì‹œ ì›ë˜ì˜ ë°ì´í„°(3ì°¨ì›)ë¡œ ë³€í™˜í•´ì£¼ëŠ” ì‘ì—…ì„ í•´ì•¼ë¨

  <img src="/assets/images/è®¡è§†/myNote/gif/col2im.gif" alt="col2im" style="zoom: 60%;" />

  

- im2colë¥¼ ì‚¬ìš©í•˜ë©´ ì—°ì‚° ì†ë„ëŠ” ë¹ ë¥´ë‹¤. 

  - í•˜ì§€ë§Œ ì—°ì‚°í•´ì•¼í•˜ëŠ” ë°ì´í„° ìˆ˜ê°€ ëŠ˜ì–´ë‚¬ê¸° ë•Œë¬¸ì— ì—°ì‚° ë©”ëª¨ë¦¬ê°€ ì¦ê°€í•œë‹¤ëŠ” ë‹¨ì ë„ ì¡´ì¬í•œë‹¤.



###### Fast Fourier Transform (FFT)

 <img src="/assets/images/è®¡è§†/myNote/pic04/32-42screenshot.png" alt="32-42screenshot" style="zoom:33%;" />

- Filterê°€ í´ ê²½ìš°(7x7) íš¨ê³¼ê°€ ìƒë‹¹íˆ ìˆì§€ë§Œ Filterê°€ ì‘ì„ ê²½ìš°(3x3) íš¨ê³¼ê°€ ê·¸ë‹¤ì§€ í¬ì§€ ì•ŠìŒ



###### Fast Algorithms

- Strassen's Algoritmì„ ì‚¬ìš©í•˜ì—¬ matrix multiplication ë³µì¡ë„ë¥¼ ì¤„ì„
- Details : <a href="https://arxiv.org/abs/1509.09308">Paper</a>



##### Floating point precision

- ì¼ë°˜ì ìœ¼ë¡œ í”„ë¡œê·¸ë˜ë°ì—ì„œëŠ” 64bit (double precision)ê°€ default

- ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ 32bit (single precision)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ 

- ìš”ì¦˜ 16bit (half precision)ë„ ì§€ì›í•˜ëŠ” library ë„ ìˆìŒ 

  - í•˜ì§€ë§Œ Floating point precision ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ 
  - 16bit (half precision)ë¡œ Trainingê³¼ Testingë¥¼ í•  ê²½ìš° errorë¥ ì´ ë°œì‚°í•¨
    - Stochastic rounding ë°©ë²• : parameter ì™€ activationì„ ëª¨ë‘ 16bitë¡œ ì¼ë‹¨ ìƒì„±í•œ ë‹¤ìŒ ê³±ì…‰ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” ê²½ìš°ì— ë” ë†’ì€ bitë¡œ ì ì‹œ ì˜¬ë ¤ ì¤¬ë‹¤ê°€ ê³±ì…‰ì—°ì‚°ì´ ëë‚˜ë©´ ë‹¤ì‹œ ë‚®ì¶”ëŠ” ë°©ì‹
    - Stochastic rounding ë¥¼ ì ìš©í–ˆì„ ë•Œ errorë¥ ì´ ìˆ˜ë ´í•˜ëŠ”ë° ì„±ê³µì„ í•¨

- 2016ë…„ì—ëŠ” parameter ì™€ activationì„ ëª¨ë‘ 1bitë¡œ í•™ìŠµì„ ì‹œí‚¤ëŠ” ëª¨ë¸ì„ ì œì•ˆí•¨ (BinaryNet)

  - ëª¨ë“  parameter ì™€ activationëŠ” +1 ë˜ëŠ” -1 ë¡œ ì„¤ì • 

    - ë‹¨, gradientëŠ” ì¢€ ë” ë†’ì€ precisionì„ ì‚¬ìš©í•¨ 

  - Bitwise XNOR ì—°ì‚°ì„ í™œìš©í•´ì„œ ë¹ ë¥¸ ê³±ì…‰ì„ ìˆ˜í–‰í•¨

    



***

ã€ŠReferenceã€‹

1.  <a href="https://www.youtube.com/watch?v=5t1E3LZ3FDY&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=6">Youtube</a>
2. <a href="https://vision4me.tistory.com/5">BlogÂ -Â GAP</a>
3. <a href="https://cs231n.github.io/">Course Site</a>
4. <a href="https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk/learning-resources/cnn-architectures/deep-learning-convolutional-neural-networks-computer-vision">QualcommÂ explanation</a>
5. <a href="https://poloclub.github.io/cnn-explainer/">CNN Workflow Visualization</a>
6. <a href="https://hackmd.io/@bouteille/B1Cmns09I#II-Backward-propagation">Blog - im2col</a>

***

